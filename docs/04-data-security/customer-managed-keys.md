# Customer-Managed Keys (CMK) for Fabric Workspaces

> **Source:** [Customer-managed keys for Fabric workspaces](https://learn.microsoft.com/en-us/fabric/security/workspace-customer-managed-keys)
> Last reviewed: 2026-02-24

## What It Is

By default, all Fabric data at rest is encrypted using **Microsoft-managed keys**. Customer-managed keys (CMK) add a second layer: your own Azure Key Vault key encrypts the Microsoft-managed data encryption key. This is **envelope encryption**:

```
Your data → encrypted by DEK (Data Encryption Key, Microsoft-managed)
DEK → encrypted by KEK (Key Encryption Key, your Azure Key Vault key)
```

The KEK never leaves Azure Key Vault. Fabric wraps/unwraps the DEK using the KEK. Revoking the KEK blocks all access to the workspace's encrypted data within ~60 minutes.

## Supported Items

CMK is currently supported for:

- Lakehouse
- Warehouse
- Notebook
- Environment
- Spark Job Definition
- API for GraphQL
- ML Model
- Experiment
- Pipeline
- Dataflow
- Industry solutions
- Mirrored Database
- SQL Database (Preview)

> If a workspace contains **unsupported items**, CMK cannot be enabled until those items are removed. Once CMK is enabled, only supported items can be created in that workspace.

For per-item CMK support status, see [feature-availability.md](../00-overview/feature-availability.md).

## What CMK Does NOT Protect

Even with CMK enabled, the following data is NOT protected by customer-managed keys:

- Lakehouse column names, table format, table compression metadata
- Data stored in Spark cluster temp storage (shuffle data, spills, RDD caches) — this applies to all Spark jobs: notebooks, Spark Job Definitions, Lakehouse Table Load/Maintenance, Shortcut Transforms, Fabric Materialized View Refresh
- Job logs stored in Spark history server
- Libraries attached in environments or via Spark session magic commands
- Metadata generated by Pipeline and Copy Job (DB name, table, schema)
- ML model and experiment metadata (model name, version, metrics)
- Warehouse query cache from Object Explorer; backend cache (evicted after each use)

> **Enterprise note**: The Spark temp storage exclusion is significant. If your compliance requirement is that ALL data must be encrypted with customer-managed keys, CMK alone does not meet that bar for any Spark-based workload.

## Setup Requirements

### Azure Key Vault Requirements

| Requirement | Detail |
|-------------|--------|
| Key type | RSA or RSA-HSM |
| Key sizes | 2,048, 3,072, or 4,096 bit (4,096 not supported for SQL DB in Fabric) |
| Soft delete | Must be enabled |
| Purge protection | Must be enabled |
| Key format | **Versionless key** only: `https://{vault-name}.vault.azure.net/{key-type}/{key-name}` |
| Auto-rotation | Fabric checks for new key version daily; uses latest version; wait 24 hours after creating a new version before disabling the old one |
| Key Vault firewall | Supported — enable "Allow Trusted Microsoft Services to bypass this firewall" |
| Managed HSM | Supported |

### Setup Steps

1. **Enable tenant setting**: Fabric administrator enables "Apply customer-managed keys" in the Admin portal
2. **Create service principal**: An Entra admin creates a service principal for the **Fabric Platform CMK** app (app ID: `61d6811f-7544-4e75-a1e6-1c59c0383311`) in the tenant
3. **Configure Azure Key Vault**: Grant the Fabric Platform CMK service principal the **Key Vault Crypto Service Encryption User** role (or a role with get, wrapkey, unwrapkey permissions)
4. **Create a key** in Azure Key Vault
5. **Enable CMK in workspace**: Workspace admin enables CMK in workspace settings → Encryption → Apply customer-managed keys, provides the key identifier

### Monitoring

Audit log operation names for CMK actions:
- `ApplyWorkspaceEncryption`
- `DisableWorkspaceEncryption`
- `GetWorkspaceEncryption`

Workspace settings → Encryption tab shows encryption status: Active, In Progress, or Failed.

## Revoking CMK Access

Revoke the key in Azure Key Vault (change access policy, delete key, or change permissions). Within ~60 minutes, all read and write operations to the workspace fail.

To restore: reinstate access to the key in Key Vault.

**SQL Database exception**: The workspace does NOT automatically revalidate the key for SQL Database in Fabric after restoration. The user must manually revalidate the CMK to restore access.

## Disabling CMK

Go to workspace settings → Encryption → disable "Apply customer-managed keys". The workspace reverts to Microsoft-managed keys. CMK cannot be disabled while encryption is in progress for any item.

## Limitations

| Limitation | Detail |
|-----------|--------|
| SKU requirement | F SKU only; Trial capacities not supported |
| BYOK interaction | CMK cannot be enabled for workspaces with BYOK enabled; CMK workspaces cannot move to BYOK-enabled capacities |
| API support | CMK can only be enabled via the Fabric portal (no API support) |
| Tenant setting dependency | Once the tenant encryption setting is off, CMK cannot be enabled/disabled for any workspace in that tenant; existing CMK workspaces remain encrypted with the customer key |
| Unsupported items | Workspace must not contain unsupported items for CMK to be enabled |

## Alternative: CMK via External Storage + Shortcuts

For data that must be encrypted with CMK and is not covered by workspace CMK (e.g., Spark temp storage), an alternative pattern is to keep data on external storage (ADLS Gen2, AWS S3, GCS) that has CMK enabled, and access it via OneLake shortcuts.

- Fabric performs in-place reads on the external CMK-encrypted data
- ADLS Gen2 shortcuts support write operations (written data is also CMK-encrypted by the storage account)
- Disable shortcut caching for S3, GCS, and S3-compatible shortcuts (cached data lands in OneLake without CMK)
- Supported workloads: Lakehouse (ADLS Gen2, S3, S3-compatible shortcuts) and KQL database shortcuts
